# MAB_introduction_and_application
How to to recommend to users based on contents, user profile, and the historical engagement of the user behavior? In this introduction, we implement several MAB learners and pick up recent machine learning publications to implement and apply them.

Multi-armed bandits (MABs) are a powerful tool in statistical machine learning: from bridging decision
making, control, optimisation and learning; address practical problems of sequential decision making while
backed by elegant theoretical guarantees; MABs are relatively easily implemented, efficient to run, and are used
in many industrial applications. 

MABs are neither fully supervised nor unsupervised, being partial supervised by
indirect rewards-as a subroutine they employ supervised learning for predicting future rewards. Exploitation
behaviour in MABs optimises short-term rewards by acting greedily based on current knowledge; but this must
be balanced against imprecision in knowledge by exploration; and when effectively balanced, MABs optimise
for long-term cumulative reward. 

In this introdution, several MAB learners are introduced and implemented from machine learning publications.

For further interested about the application,\
ðŸ‘‰ðŸ‘‰here you go: [A Survey on Practical Applications of Multi-Armed and Contextual Bandits](https://arxiv.org/abs/1904.10040)
